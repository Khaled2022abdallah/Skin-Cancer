{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTCG2LOJgABW"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpNOTxwhnzZk"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NuegbCinzSL"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3ViWv2OnzJI"
      },
      "outputs": [],
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJbkV_sdoFLC"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuaMuuj6oFEE"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d fanconic/skin-cancer-malignant-vs-benign"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4S683aWoE6M"
      },
      "outputs": [],
      "source": [
        "! unzip skin-cancer-malignant-vs-benign.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7g1WCrupMeT"
      },
      "outputs": [],
      "source": [
        "# !pip install scikit_plot\n",
        "# !pip install sklearn\n",
        "# !pip install labelencoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ9umzQ0fit2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHhwbLfmfv2u"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    EPOCHS = 5\n",
        "    BATCH_SIZE = 32\n",
        "    SEED = 42\n",
        "    TF_SEED = 768\n",
        "    HEIGHT = 224\n",
        "    WIDTH = 224\n",
        "    CHANNELS = 3\n",
        "    IMAGE_SIZE = (224, 224, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urt_CfyYf1rG"
      },
      "outputs": [],
      "source": [
        "TRAIN_PATH_begin = '/content/data/train/benign'\n",
        "TRAIN_PATH_malignant = '/content/data/train/malignant'\n",
        "TEST_PATH_benign= '/content/data/test/benign'\n",
        "TEST_PATH_malignant='/content/data/test/malignant'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "205kBG6FEffj"
      },
      "outputs": [],
      "source": [
        "train_images = glob.glob(f\"{TRAIN_PATH_begin}**/*.jpg\")+glob.glob(f\"{TRAIN_PATH_malignant}**/*.jpg\")\n",
        "test_images = glob.glob(f\"{TEST_PATH_malignant}**/*.jpg\")+glob.glob(f\"{TEST_PATH_benign}**/*.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfDHrMuKEl6K"
      },
      "outputs": [],
      "source": [
        "# Get train & test set sizes\n",
        "train_size = len(train_images)\n",
        "test_size = len(test_images)\n",
        "\n",
        "# Get dataset size\n",
        "total = train_size + test_size\n",
        "\n",
        "# View samples counts\n",
        "print(f'train samples count:\\t\\t{train_size}')\n",
        "print(f'test samples count:\\t\\t{test_size}')\n",
        "print('=======================================')\n",
        "print(f'TOTAL:\\t\\t\\t\\t{total}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhN8fmHlEpWW"
      },
      "outputs": [],
      "source": [
        "def generate_labels(labels):\n",
        "    return [label.split('/')[-2:][0] for label in labels]\n",
        "\n",
        "def build_df(image_paths, labels):\n",
        "    # Create dataframe\n",
        "    df = pd.DataFrame({\n",
        "        'image_path': image_paths,\n",
        "        'label': generate_labels(labels)\n",
        "    })\n",
        "    \n",
        "    # Generate label encodings\n",
        "    df['label'] = df.apply(lambda row: 0 if row.label == 'malignant' else 1, axis=1)\n",
        "    \n",
        "    # Shuffle and return df\n",
        "    return df.sample(frac=1, random_state=CFG.SEED).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6fqt-duJ_kj"
      },
      "outputs": [],
      "source": [
        "print(len(train_images))\n",
        "print(len(generate_labels(train_images)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSjUkiu0EtrP"
      },
      "outputs": [],
      "source": [
        "# Build the DataFrames\n",
        "train_df = build_df(train_images, generate_labels(train_images))\n",
        "test_df = build_df(test_images, generate_labels(test_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHbqfae9Ewhp"
      },
      "outputs": [],
      "source": [
        "# View first 5 samples in the training set\n",
        "train_df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jgn9HZhMVVJ"
      },
      "outputs": [],
      "source": [
        "test_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fjwhQ1WUXiH"
      },
      "outputs": [],
      "source": [
        "def _load(image_path):\n",
        "    # Read and decode an image file to a uint8 tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_jpeg(image, channels=3)\n",
        "    \n",
        "    # Resize image\n",
        "    image = tf.image.resize(image, [CFG.HEIGHT, CFG.WIDTH],\n",
        "                            method=tf.image.ResizeMethod.LANCZOS3)\n",
        "    \n",
        "    # Convert image dtype to float32 and NORMALIZE!!!\n",
        "    image = tf.cast(image, tf.float32)/255.\n",
        "    \n",
        "    # Return image\n",
        "    return image\n",
        "\n",
        "def view_sample(image, label):\n",
        "    plt.figure(figsize=(8, 10))\n",
        "    plt.imshow(image)\n",
        "    plt.title(f'Label: {label}', fontsize=16)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2JhMYi5U5bR"
      },
      "outputs": [],
      "source": [
        "# Select random sample from train_df\n",
        "import random\n",
        "\n",
        "idx = random.sample(train_df.index.to_list(), 1)[0]\n",
        "\n",
        "# Load the random sample and label\n",
        "sample_image, sample_label = _load(train_df.image_path[idx]), train_df.label[idx]\n",
        "\n",
        "# View the random sample\n",
        "view_sample(sample_image, sample_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcGSJot_U-ir"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, figsize=(14, 10))\n",
        "\n",
        "# Set the spacing between subplots\n",
        "fig.tight_layout(pad=6.0)\n",
        "\n",
        "# Plot Train Labels Distribution\n",
        "ax1.set_title('Train Labels Distribution', fontsize=20)\n",
        "train_distribution = train_df['label'].value_counts().sort_values()\n",
        "sns.barplot(x=train_distribution.values,\n",
        "            y=list(train_distribution.keys()),\n",
        "            orient=\"h\",\n",
        "            ax=ax1)\n",
        "\n",
        "# Plot Test Labels Distribution\n",
        "ax2.set_title('Test Labels Distribution', fontsize=20)\n",
        "test_distribution = test_df['label'].value_counts().sort_values()\n",
        "sns.barplot(x=test_distribution.values,\n",
        "            y=list(test_distribution.keys()),\n",
        "            orient=\"h\",\n",
        "            ax=ax2);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4orKgSyVVhyV"
      },
      "outputs": [],
      "source": [
        "# Create Train/Val split with Training Set\n",
        "train_split_idx, val_split_idx, _, _ = train_test_split(train_df.index, \n",
        "                                                        train_df.label, \n",
        "                                                        test_size=0.15,\n",
        "                                                        stratify=train_df.label,\n",
        "                                                        random_state=CFG.SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OMMWWxvVrwq"
      },
      "outputs": [],
      "source": [
        "# Get new training and validation data\n",
        "train_new_df = train_df.iloc[train_split_idx].reset_index(drop=True)\n",
        "val_df = train_df.iloc[val_split_idx].reset_index(drop=True)\n",
        "\n",
        "# View shapes\n",
        "train_new_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzKVoATuVzkQ"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, figsize=(14, 10))\n",
        "\n",
        "# Set the spacing between subplots\n",
        "fig.tight_layout(pad=6.0)\n",
        "\n",
        "# Plot New Train Labels Distribution\n",
        "ax1.set_title('New Train Labels Distribution', fontsize=20)\n",
        "train_new_distribution = train_new_df['label'].value_counts().sort_values()\n",
        "sns.barplot(x=train_new_distribution.values,\n",
        "            y=list(train_new_distribution.keys()),\n",
        "            orient=\"h\",\n",
        "            ax=ax1)\n",
        "\n",
        "# Plot Validation Labels Distribution\n",
        "ax2.set_title('Validation Labels Distribution', fontsize=20)\n",
        "val_distribution = val_df['label'].value_counts().sort_values()\n",
        "sns.barplot(x=val_distribution.values,\n",
        "            y=list(val_distribution.keys()),\n",
        "            orient=\"h\",\n",
        "            ax=ax2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjFrS8BkV7Uk"
      },
      "outputs": [],
      "source": [
        "# Build augmentation layer\n",
        "augmentation_layer = Sequential([\n",
        "    layers.RandomFlip(mode='horizontal_and_vertical', seed=CFG.TF_SEED),\n",
        "    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1), seed=CFG.TF_SEED),\n",
        "], name='augmentation_layer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2gXCEwcWCK6"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 10))\n",
        "\n",
        "# Set the spacing between subplots\n",
        "fig.tight_layout(pad=6.0)\n",
        "\n",
        "# View Original Image\n",
        "ax1.set_title('Original Image', fontsize=20)\n",
        "ax1.imshow(sample_image);\n",
        "\n",
        "# View Augmented Image\n",
        "ax2.set_title('Augmented Image', fontsize=20)\n",
        "ax2.imshow(augmentation_layer(sample_image));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsygHaK3WFt_"
      },
      "outputs": [],
      "source": [
        "def encode_labels(labels, encode_depth=2):\n",
        "    return tf.one_hot(labels, depth=encode_depth).numpy()\n",
        "\n",
        "def create_pipeline(df, load_function, augment=False, batch_size=32, shuffle=False, cache=None, prefetch=False):\n",
        "    '''\n",
        "    Generates an input pipeline using the tf.data API given a Pandas DataFrame and image loading function.\n",
        "    \n",
        "    @params\n",
        "        - df: (pd.DataFrame) -> DataFrame containing paths and labels \n",
        "        - load_function: (function) -> function used to load images given their paths\n",
        "        - augment: (bool) -> condition for applying augmentation\n",
        "        - batch_size: (int) -> size for batched (default=32) \n",
        "        - shuffle: (bool) -> condition for data shuffling, data is shuffled when True (default=False)\n",
        "        - cache: (str) -> cache path for caching data, data is not cached when None (default=None)\n",
        "        - prefetch: (bool) -> condition for prefeching data, data is prefetched when True (default=False)\n",
        "        \n",
        "    @returns\n",
        "        - dataset: (tf.data.Dataset) -> dataset input pipeline used to train a TensorFlow model\n",
        "    '''\n",
        "    # Get image paths and labels from DataFrame\n",
        "    image_paths = df.image_path\n",
        "    image_labels = encode_labels(df.label)\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    \n",
        "    # Create dataset with raw data from DataFrame\n",
        "    ds = tf.data.Dataset.from_tensor_slices((image_paths, image_labels))\n",
        "    \n",
        "    # Map augmentation layer and load function to dataset inputs if augment is True\n",
        "    # Else map only the load function\n",
        "    if augment:\n",
        "        ds = ds.map(lambda x, y: (augmentation_layer(load_function(x)), y), num_parallel_calls=AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (load_function(x), y), num_parallel_calls=AUTOTUNE)\n",
        "    \n",
        "    # Apply shuffling based on condition\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=1000)\n",
        "        \n",
        "    # Apply batching\n",
        "    ds = ds.batch(batch_size)\n",
        "    \n",
        "    # Apply caching based on condition\n",
        "    # Note: Use cache in memory (cache='') if the data is small enough to fit in memory!!!\n",
        "    if cache != None:\n",
        "        ds = ds.cache(cache)\n",
        "    \n",
        "    # Apply prefetching based on condition\n",
        "    # Note: This will result in memory trade-offs\n",
        "    if prefetch:\n",
        "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "    \n",
        "    # Return the dataset\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28_bdxZCWM4n"
      },
      "outputs": [],
      "source": [
        "# Generate Train Input Pipeline\n",
        "train_ds = create_pipeline(train_new_df, _load, augment=True, \n",
        "                           batch_size=CFG.BATCH_SIZE, \n",
        "                           shuffle=False, prefetch=True)\n",
        "\n",
        "# Generate Validation Input Pipeline\n",
        "val_ds = create_pipeline(val_df, _load, \n",
        "                         batch_size=CFG.BATCH_SIZE, \n",
        "                         shuffle=False, prefetch=False)\n",
        "\n",
        "# Generate Test Input Pipeline\n",
        "test_ds = create_pipeline(test_df, _load, \n",
        "                          batch_size=CFG.BATCH_SIZE, \n",
        "                          shuffle=False, prefetch=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nalTTeEmWRaf"
      },
      "outputs": [],
      "source": [
        "def cnn_model():\n",
        "    \n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "    \n",
        "    cnn_sequential = Sequential([\n",
        "        layers.Input(shape=CFG.IMAGE_SIZE, dtype=tf.float32, name='input_image'),\n",
        "        \n",
        "        layers.Conv2D(16, kernel_size=3, activation='relu', kernel_initializer=initializer),\n",
        "        layers.Conv2D(16, kernel_size=3, activation='relu', kernel_initializer=initializer),\n",
        "        layers.MaxPool2D(pool_size=2, padding='valid'),\n",
        "        \n",
        "        layers.Conv2D(8, kernel_size=3, activation='relu', kernel_initializer=initializer),\n",
        "        layers.Conv2D(8, kernel_size=3, activation='relu', kernel_initializer=initializer),\n",
        "        layers.MaxPool2D(pool_size=2),\n",
        "        \n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
        "        layers.Dense(2, activation='sigmoid', kernel_initializer=initializer)\n",
        "    ], name='cnn_sequential_model')\n",
        "    \n",
        "    return cnn_sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNg8ZdBhWl0E"
      },
      "outputs": [],
      "source": [
        "# Generate Model\n",
        "model_cnn = cnn_model()\n",
        "\n",
        "# Generate Summary of the Model\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkfoKu5eWs3O"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, callbacks_list, tf_train_data, \n",
        "                tf_valid_data=None, shuffling=False):\n",
        "    '''\n",
        "        Trains a TensorFlow model and returns a dict object containing the model metrics history data. \n",
        "        \n",
        "        @params\n",
        "        - model: (tf.keras.model) -> model to be trained \n",
        "        - num_epochs: (int) -> number of epochs to train the model\n",
        "        - callbacks_list: (list) -> list containing callback fuctions for model\n",
        "        - tf_train_data: (tf.data.Dataset) -> dataset for model to be train on \n",
        "        - tf_valid_data: (tf.data.Dataset) -> dataset for model to be validated on (default=None)\n",
        "        - shuffling: (bool) -> condition for data shuffling, data is shuffled when True (default=False)\n",
        "        \n",
        "        @returns\n",
        "        - model_history: (dict) -> dictionary containing loss and metrics values tracked during training\n",
        "    '''\n",
        "    \n",
        "    model_history = {}\n",
        "    \n",
        "    if tf_valid_data != None:\n",
        "        model_history = model.fit(tf_train_data,\n",
        "                                  epochs=num_epochs,\n",
        "                                  validation_data=tf_valid_data,\n",
        "                                  validation_steps=int(len(tf_valid_data)),\n",
        "                                  callbacks=callbacks_list,\n",
        "                                  shuffle=shuffling)\n",
        "        \n",
        "    if tf_valid_data == None:\n",
        "        model_history = model.fit(tf_train_data,\n",
        "                                  epochs=num_epochs,\n",
        "                                  callbacks=callbacks_list,\n",
        "                                  shuffle=shuffling)\n",
        "    return model_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKN3sjbBWzlt"
      },
      "outputs": [],
      "source": [
        "# Define Early Stopping Callback\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    patience=3, \n",
        "    restore_best_weights=True)\n",
        "\n",
        "# Define Reduce Learning Rate Callback\n",
        "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    factor=0.1,\n",
        "    verbose=1)\n",
        "\n",
        "# Define Callbacks and Metrics lists\n",
        "CALLBACKS = [early_stopping_callback, reduce_lr_callback]\n",
        "METRICS = ['accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W8nwB3AW4aK"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(CFG.SEED)\n",
        "\n",
        "# Compile the model\n",
        "model_cnn.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=METRICS\n",
        ")\n",
        "\n",
        "\n",
        "cnn_history = train_model(\n",
        "    model_cnn, CFG.EPOCHS, CALLBACKS, \n",
        "    train_ds, val_ds,\n",
        "    shuffling=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX2aOj7wW9bu"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "cnn_evaluation = model_cnn.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arO81Sj8Xkgi"
      },
      "outputs": [],
      "source": [
        "# Generate model probabilities and associated predictions\n",
        "cnn_test_probabilities = model_cnn.predict(test_ds, verbose=1)\n",
        "cnn_test_predictions = tf.argmax(cnn_test_probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNYSL4NaXmvS"
      },
      "outputs": [],
      "source": [
        "# Here's a function to get any model/preprocessor from tensorflow hub\n",
        "def get_tfhub_model(model_link, model_name, model_trainable=False):\n",
        "    return hub.KerasLayer(model_link,\n",
        "                          trainable=model_trainable,\n",
        "                          name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmWFFZnya2gy"
      },
      "outputs": [],
      "source": [
        "# Get EfficientNet V2 B0 here\n",
        "efficientnet_v2_url = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b0/feature_vector/2'\n",
        "model_name = 'efficientnet_v2_b0'\n",
        "\n",
        "# Set trainable to False for inference-only \n",
        "set_trainable=False\n",
        "\n",
        "efficientnet_v2_b0 = get_tfhub_model(efficientnet_v2_url, \n",
        "                                     model_name, \n",
        "                                     model_trainable=set_trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5oFcan6a6mT"
      },
      "outputs": [],
      "source": [
        "def efficientnet_v2_model():\n",
        "    \n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "    \n",
        "    efficientnet_v2_sequential = Sequential([\n",
        "        layers.Input(shape=CFG.IMAGE_SIZE, dtype=tf.float32, name='input_image'),\n",
        "        efficientnet_v2_b0,\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
        "        layers.Dense(2, dtype=tf.float32, activation='sigmoid', kernel_initializer=initializer)\n",
        "    ], name='efficientnet_v2_sequential_model')\n",
        "    \n",
        "    return efficientnet_v2_sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYm-JkApbAeW"
      },
      "outputs": [],
      "source": [
        "# Generate Model\n",
        "model_efficientnet_v2 = efficientnet_v2_model()\n",
        "\n",
        "# Generate Summary of the Model\n",
        "model_efficientnet_v2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aXqzZxLbHRz"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(CFG.SEED)\n",
        "\n",
        "# Compile the model\n",
        "model_efficientnet_v2.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=METRICS\n",
        ")\n",
        "\n",
        "# Train the model \n",
        "print(f'Training {model_efficientnet_v2.name}.')\n",
        "print(f'Train on {len(train_new_df)} samples, validate on {len(val_df)} samples.')\n",
        "print('----------------------------------')\n",
        "\n",
        "efficientnet_v2_history = train_model(\n",
        "    model_efficientnet_v2, CFG.EPOCHS, CALLBACKS, \n",
        "    train_ds, val_ds,\n",
        "    shuffling=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QrrosV-bLh3"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "efficientnet_v2_evaluation = model_efficientnet_v2.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHLYhiibbQqv"
      },
      "outputs": [],
      "source": [
        "# Generate model probabilities and associated predictions\n",
        "efficientnet_v2_test_probabilities = model_efficientnet_v2.predict(test_ds, verbose=1)\n",
        "efficientnet_v2_test_predictions = tf.argmax(efficientnet_v2_test_probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9l0cSujbTTY"
      },
      "outputs": [],
      "source": [
        "!pip install -q vit-keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqgJyJ54clqW"
      },
      "outputs": [],
      "source": [
        "# !pip install vit\n",
        "# !pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wez71w1mbYe9"
      },
      "outputs": [],
      "source": [
        "from vit_keras import vit\n",
        "\n",
        "# Download the model\n",
        "vit_model = vit.vit_b16(\n",
        "        image_size=224,\n",
        "        activation='softmax',\n",
        "        pretrained=True,\n",
        "        include_top=False,\n",
        "        pretrained_top=False,\n",
        "        classes=2)\n",
        "\n",
        "# Freeze model layers for inference-mode only\n",
        "for layer in vit_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkC8A3zmcVd6"
      },
      "outputs": [],
      "source": [
        "def vit_b16_model():\n",
        "    \n",
        "    initializer = tf.keras.initializers.GlorotNormal()\n",
        "    \n",
        "    vit_b16_sequential = Sequential([\n",
        "        layers.Input(shape=CFG.IMAGE_SIZE, dtype=tf.float32, name='input_image'),\n",
        "        vit_model,\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu', kernel_initializer=initializer),\n",
        "        layers.Dense(2, dtype=tf.float32, activation='sigmoid', kernel_initializer=initializer)\n",
        "    ], name='vit_b16_sequential_model')\n",
        "    \n",
        "    return vit_b16_sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_BtmHNudg0U"
      },
      "outputs": [],
      "source": [
        "# Generate Model\n",
        "model_vit_b16 = vit_b16_model()\n",
        "\n",
        "# Generate Summary of the Model\n",
        "model_vit_b16.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5BRH4Wedk2y"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(CFG.SEED)\n",
        "\n",
        "# Compile the model\n",
        "model_vit_b16.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    metrics=METRICS\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "vit_b16_history = train_model(\n",
        "    model_vit_b16, CFG.EPOCHS, CALLBACKS, \n",
        "    train_ds, val_ds,\n",
        "    shuffling=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooT09QdtdvF9"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "vit_b16_evaluation = model_vit_b16.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpA0F7E-eIjk"
      },
      "outputs": [],
      "source": [
        "# Generate model probabilities and associated predictions\n",
        "vit_b16_test_probabilities = model_vit_b16.predict(test_ds, verbose=1)\n",
        "vit_b16_test_predictions = tf.argmax(vit_b16_test_probabilities, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTphQyNZeJDs"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes='auto', figsize=(10, 10), text_size=12): \n",
        "    # Generate confusion matrix \n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Set plot size\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    # Create confusion matrix heatmap\n",
        "    disp = sns.heatmap(\n",
        "        cm, annot=True, cmap='Greens',\n",
        "        annot_kws={\"size\": text_size}, fmt='g',\n",
        "        linewidths=1, linecolor='black', clip_on=False,\n",
        "        xticklabels=classes, yticklabels=classes)\n",
        "    \n",
        "    # Set title and axis labels\n",
        "    disp.set_title('Confusion Matrix', fontsize=24)\n",
        "    disp.set_xlabel('Predicted Label', fontsize=20) \n",
        "    disp.set_ylabel('True Label', fontsize=20)\n",
        "    plt.yticks(rotation=0) \n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.show()\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7gldY_meYv4"
      },
      "outputs": [],
      "source": [
        "class_names = ['malignant', 'benign']\n",
        "\n",
        "plot_confusion_matrix(\n",
        "    test_df.label, \n",
        "    cnn_test_predictions, \n",
        "    figsize=(8, 8), \n",
        "    classes=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrF8RP-eeqs0"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(\n",
        "    test_df.label, \n",
        "    efficientnet_v2_test_predictions, \n",
        "    figsize=(8, 8),  \n",
        "    classes=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJZ3bRX3eren"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(\n",
        "    test_df.label, \n",
        "    vit_b16_test_predictions, \n",
        "    figsize=(8, 8), \n",
        "    classes=class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtGUqK6ZewoM"
      },
      "outputs": [],
      "source": [
        "# CNN ROC Curves\n",
        "print(classification_report(test_df.label, \n",
        "                            cnn_test_predictions, \n",
        "                            target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAl6wkCMe3ga"
      },
      "outputs": [],
      "source": [
        "# EfficientNet V2 ROC Curves\n",
        "print(classification_report(test_df.label, \n",
        "                            efficientnet_v2_test_predictions, \n",
        "                            target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7tlE4C_e7Bi"
      },
      "outputs": [],
      "source": [
        "# ViT-b16 ROC Curves\n",
        "print(classification_report(test_df.label, \n",
        "                            vit_b16_test_predictions, \n",
        "                            target_names=class_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}